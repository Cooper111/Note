**增删改数据（DML)，是加字段等修改表结构的操作（DDL）**



参考链接

- <https://zhuanlan.zhihu.com/p/29150809>
- <https://www.jianshu.com/p/d2ac26ca6525>
- 还有极客时间的MySQL实战45讲
- 【好！！！】[MySQL 死锁系列- 锁的类型以及加锁原理！](<https://mp.weixin.qq.com/s?__biz=MzU0OTk3ODQ3Ng==&mid=2247487226&idx=1&sn=5f14a424c394e442ddc7ea6ad653af30&chksm=fba6e6f9ccd16fef31ea7c280e12c8624cfc47beb49cd3611e76beb6f57abf997c38d3964af1&mpshare=1&scene=23&srcid=&sharer_sharetime=1586071860054&sharer_shareid=e6d90aec84add5cf004cb1ab6979727c#rd>)
- [超全面MySQL语句加锁分析（上篇）（求转）](<https://mp.weixin.qq.com/s?__biz=MzIxNTQ3NDMzMw==&mid=2247484169&idx=1&sn=f06eac890ea0f0810cedd6a2ca62fdd3&chksm=97968afba0e103ed979f2c0e75448cc78c42b094a895e1d43eb9cd81da97c013146621e422ea&mpshare=1&scene=23&srcid=&sharer_sharetime=1587870328788&sharer_shareid=e6d90aec84add5cf004cb1ab6979727c#rd>)
- [一分钟深入Mysql的意向锁——《深究Mysql锁》](<https://blog.csdn.net/zcl_love_wx/article/details/82015281>)
- [大厂必问锁机制](<https://mp.weixin.qq.com/s?__biz=MzU1MzE4OTU0OQ==&mid=2247484473&idx=1&sn=e1093c8ebc4e6b105dbd41e1065ad0e8&chksm=fbf7edfbcc8064edf01f40dced8d72b1fcc499bd2aa1eeecda15b863eefa7c2a08e075417779&mpshare=1&scene=23&srcid=&sharer_sharetime=1592830518666&sharer_shareid=e6d90aec84add5cf004cb1ab6979727c#rd>)

- 【全】[Mysql锁机制](<https://blog.csdn.net/qq_44766883/article/details/105879308>)



# 全局锁

多用于做全库逻辑备份

在可重复读隔离级别下开启一个事务来拿到一致性视图。

当 mysqldump 使用参数**–single-transaction** 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。

MySQL 提供了一个**加全局读锁**的方法，命令是 **Flush tables with read lock (FTWRL)**





# 表锁

- lock tables … read/write

- MDL元数据锁
  - 读锁
  - 写锁

  当对一个表做增删改查操作的时候，加 MDL 读锁；

  当要对表做结构变更操作的时候，加 MDL 写锁。

  事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

- 当备库用–single-transaction 做逻辑备份的时候，如果从主库的 binlog 传来一个 DDL 语句会怎么样？

  ```mysql
  /* Q1为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1) */
  Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
  /* 启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)*/
  Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
  /* other tables */
  /* 设置一个保存点，这个很重要（Q3） */
  Q3:SAVEPOINT sp;
  /* 时刻 1 没有影响，备份拿到的是 DDL 后的表结构*/
  /* show create 是为了拿到表结构 (Q4) */
  Q4:show create table `t1`;
  /* 时刻 2 则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；*/
  /* 然后正式导数据 （Q5 */
  Q5:SELECT * FROM `t1`;
  /* 时刻 3 mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。*/
  /* 回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6） */
  Q6:ROLLBACK TO SAVEPOINT sp;
  /* 时刻 4 mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。*/
  /* other tables */
  ```





# 行锁



`innodb`行级锁是通过锁索引记录实现的。`如果update的列没建索引，即使只update一条记录也会锁定整张表`。[InnoDB行锁实现方式](https://www.cnblogs.com/aiit/p/8288050.html)

- 两阶段锁

  - 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要**等到事务结束**时才释放。这个就是**两阶段锁协议**。
  - 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放

- 死锁

  - 死锁原因：事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态

  - 解决策略

    - 一种策略是，直接进入**等待，直到超时**。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置
    - 另一种策略是，发起**死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑。

  - 消耗大量CPU资源原因：

    ​        **死锁检测复杂度O(n)。**假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务

  - #### 怎么解决由这**种热点行更新**导致的性能问题呢？

    - 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以**临时把死锁检测关掉**。

    - 另一个思路是**控制并发度**。

      ​        并发控制要做在**数据库服务端**。如果你有中间件，可以考虑在**中间件**实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 **MySQL** 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。**这样在 InnoDB 内部就不会有大量的死锁检测工作了**。

    - 如果没有专家，可以将**一行改成逻辑上的多行**来减少锁冲突

  



## 并发写问题

并发写这里先引出两个概念**，`快照读`，`当前读`**

- **快照读**：就是从当前版本的快照中进行读取，在mysql的**可重复读隔离级别**下，其他事务所有的DML操作都不会影响此种读法的结果。

  ```mysql
  #简单的查询
  select * from table;
  ```

- **当前读**：读取的是记录数据的最新版本，并且当前读返回的记录都会加上锁，保证其他事务不会再并发的修改这条记录

  ```sql
  select * from table for update 
  select * from table lock in share mode
  #所有的DML操作
  insert into table value(1,"dsa");
  delete from table where id=1;
  update table set name="dsa" where id=1;
  ```

  以update的过程为例，首先会执行当前读，然后把返回的数据加锁，之后执行update。加锁是防止别的事务在这个时候对这条记录做什么，默认加的是排他锁，这样就可以保证数据不会出错了。当然依然会出现更新丢失的问题。

## 无索引问题
加锁的过程要分有索引和无索引两种情况，比如下面这条语句

```sql
update user set age=11 where id = 1
```

id 是这张表的主键，是有索引的情况，那么 MySQL 直接就在索引数中找到了这行数据，然后干净利落的加上行锁就可以了。

而下面这条语句

```sql
update user set age=11 where age=10
```

表中并没有为 age 字段设置索引，所以， MySQL 无法直接定位到这行数据。那怎么办呢，当然也不是加表锁了。MySQL **会为这张表中所有行加行锁，没错，是所有行**。但是呢，**在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放锁，最终只留下符合条件的行**。虽然**最终只为符合条件的行加了锁，但是这一锁一释放的过程对性能也是影响极大的**。所以，如果是大表的话，建议合理设计索引，如果真的出现这种情况，那很难保证并发度。




## **共享锁与排他锁**

- 共享锁（读锁）：其他事务可以读，但不能写。
- 排他锁（写锁） ：其他事务不能读取，也不能写。





## **粒度锁**

MySQL 不同的存储引擎支持不同的锁机制，所有的存储引擎**都以自己的方式显现了锁机制**

- MyISAM 和 MEMORY 存储引擎采用的是表级锁（table-level locking）
- BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁
- InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。

===========================================================================

#### 默认情况下

表锁和行锁都是**自动获得**的， 不需要额外的命令。



#### 但是在有的情况下

用户需要**明确地**进行锁表或者进行事务的控制， 以便确保整个事务的完整性，这样就需要使**用事务控制和锁定语句**来完成。

============================================================================

## **不同粒度锁的比较：**

- 表级锁
- 行级锁
- 页面锁



# **MyISAM 表锁**

================================================================================

## **MyISAM表级锁模式：**

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；



默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。

这也正是 `MyISAM` 表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。

## **MyISAM加表锁方法：**

MyISAM 在执行**查询语句（SELECT）**前，会自动给涉及的表**加读锁**，

在执行**更新操作（UPDATE、DELETE、INSERT 等）**前，会自动给涉及的表**加写锁**，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。



MyISAM存储引擎支持并发插入，以减少给定表的读和写操作之间的争用： ——数据文件中间没有空闲块决定



## **查询表级锁争用情况：**

可以通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况：

```sql
SHOW STATUS LIKE 'Table%';
```



================================================================================





# InnoDB行级锁和表级锁

## **InnoDB锁模式：**

`InnoDB` 实现了以下两种类型的**行锁**：

- 共享锁（S）：**允许**一个事务去读一行，**阻止**其他事务获得相同数据集的**排他锁**。
- 排他锁（X）：**允许**获得排他锁的事务更新数据，**阻止**其他事务取得相同数据集的**共享读锁和排他写锁**。



**“阻止其他事务取得相同数据集的共享读锁和排他写锁”，也就是其他事务不能使用“select ... lock in share mode”“select ... for update”“insert、update、delete”等，但是可以使用普通的select，因为普通select不需要获得锁，也不会与共享锁或排它锁冲突**



为了允许行锁和表锁共存，实现多粒度锁机制，`InnoDB` 还有两种内部使用的**意向锁**（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

**InnoDB行锁模式兼容性列表:**

|      | S    | IS   | X    | IX   |
| ---- | ---- | ---- | ---- | ---- |
| S    | 兼容 | 兼容 | 冲突 | 冲突 |
| IS   | 兼容 | 兼容 | 冲突 | 兼容 |
| X    | 冲突 | 冲突 | 冲突 | 冲突 |
| IX   | 冲突 | 兼容 | 冲突 | 兼容 |

（如果一个事务请求的锁模式与当前的锁兼容， `InnoDB` 就将请求的锁授予该事务； 反之， 如果两者不兼容，该事务就要等待锁释放。）



### 意向锁

- **作用**

  当一个事务在需要获取资源的锁定时，如果该资源已经被排他锁占用，则数据库会自动给该事务申请一个该表的意向锁。如果自己需要一个共享锁定，就申请一个**意向共享锁**。如果需要的是某行（或者某些行）的排他锁定，则申请一个**意向排他锁**。

- e.g.

  事务A锁住了一行，事务B想锁表，形成了冲突。

  有了意向锁之后，前面例子中的事务A在申请行锁（写锁）之前，数据库会自动先给事务A申请表的意向排他锁。当事务B去申请表的写锁时就会失败，因为表上有意向排他锁之后事务B申请表的写锁时会被阻塞。

- 意向锁之间都是兼容的

- **InnoDB行锁模式兼容性列表:**

  |      | S    | IS   | X    | IX   |
  | ---- | ---- | ---- | ---- | ---- |
  | S    | 兼容 | 兼容 | 冲突 | 冲突 |
  | IS   | 兼容 | 兼容 | 冲突 | 兼容 |
  | X    | 冲突 | 冲突 | 冲突 | 冲突 |
  | IX   | 冲突 | 兼容 | 冲突 | 兼容 |



## **InnoDB加锁方法：**

- **意向锁**是 InnoDB 自动加的， 不需用户干预。

- **对于 UPDATE、 DELETE 和 INSERT 语句**， `InnoDB`会自动给涉及数据集加排他锁（X)；

- 对于**普通 SELECT 语句**，InnoDB 不会加任何锁；

  事务可以通过以下语句显式给记录集加共享锁或排他锁：

- - **共享锁（S）**：**SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE**。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。
  - **排他锁（X)**：**SELECT * FROM table_name WHERE ... FOR UPDATE**。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁



- **隐式锁定：**

  `InnoDB`在事务执行过程中，使用**两阶段锁协议**：

- **显式锁定 ：**

  ```sql
  select ... lock in share mode //共享锁 
  select ... for update //排他锁 
  ```

- **select... for update：**为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的

- **select ... lock in share mode ：**只能对这些数据进行**简单的select 操作**，并不能够进行 **DML操作**

- **性能影响：**:两种锁定都有，事务没有及时的commit或者rollback 可能会造成其他事务长时间的等待，影响并发

- **for update 和 lock in share mode 的区别：**前一个上的是排他锁（X 锁），一旦一个事务获取了这个锁，其他的事务是没法在这些数据上执行 for update ；后一个是共享锁，多个事务可以同时的对相同数据执行 lock in share mode。



## **InnoDB 行锁实现方式：**

- InnoDB 行锁是通过**给索引上的索引项加锁**来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！**
- 不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使**用行锁来对数据加锁**。
- 只有执行计划真正使用了索引，才能使用行锁：即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，
  别忘了检查 SQL 的执行计划（可以通过 explain 检查 SQL 的执行计划），以确认是否真正使用了索引。（更多阅读：[MySQL索引总结](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s/h4B84UmzAUJ81iBY_FXNOg)）
- 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个session是访问不同行的记录， 但是如果是使用相同的索引键， 是会出现锁冲突的（后使用这些索引的session需要等待先使用索引的session释放锁后，才能获取锁）。 应用设计的时候要注意这一点。

  

## **InnoDB的间隙锁：**

### 加锁条件

当我们**用范围条件**而不是相等条件检索数据，并请求共享或排他锁时，`InnoDB`会给符合条件的**已有数据记录的索引项加锁**；对于键值在条件范围内但并**不存在的记录，叫做“间隙（GAP)”**，**InnoDB也会对这个“间隙”加锁**，这种锁机制就是所谓的间隙锁（Next-Key锁）。



很显然，在使用范围条件检索并锁定记录时，**InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入**，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。



### InnoDB使用间隙锁的目的

- 防止**幻读**，以满足相关隔离级别的要求；
- 满足恢复和复制的需要：



### 原则和优化（重要！牛逼！）

原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。

原则 2：查找过程中访问到的对象才会加锁。

优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

**更多例子见此**：<https://blog.csdn.net/qq_44766883/article/details/105879308>

**案例一：等值查询间隙锁**

数据库数据  id=5,10,15,20,25

![](https://img-blog.csdnimg.cn/20200327194755141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzY2ODgz,size_16,color_FFFFFF,t_70)

根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；

同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。



**案例二：非唯一索引等值锁**

![](https://img-blog.csdnimg.cn/20200327194854848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzY2ODgz,size_16,color_FFFFFF,t_70)

根据原则1，优化2，锁的范围是(0,5],(5,10)，但是根据原则2，只有访问到的对象才加锁，这个查询使用了覆盖索引，并不访问主键索引，所以主键上没加锁。
需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。



**案例三：主键索引范围锁**

![](https://img-blog.csdnimg.cn/20200327195019868.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzY2ODgz,size_16,color_FFFFFF,t_70)

开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。
范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断



**案例四：非唯一索引范围锁**

![](https://img-blog.csdnimg.cn/20200327195047318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzY2ODgz,size_16,color_FFFFFF,t_70)

这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。



**案例六：非唯一索引上存在"等值"的例子**
表中插入一条mysql> insert into t values(30,10,30);

![](https://img-blog.csdnimg.cn/20200327195203739.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0NzY2ODgz,size_16,color_FFFFFF,t_70)

这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。
然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。

**注意：**

　　**1、事务隔离级别为读提交时，写数据只会锁住相应的行**

　　**2、事务隔离级别为可重复读时，如果检索条件有索引（包括主键索引）的时候，默认加锁方式是next-key 锁；如果检索条件没有索引，更新数据时会锁住整张表。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读。**

　　**3、事务隔离级别为串行化时，读写数据都会锁住整张表**







# Mysql恢复

MySQL **通过 BINLOG** 录入执行成功的 INSERT、UPDATE、DELETE 等更新数据的 SQL 语句，并由此实现 **MySQL 数据库的恢复和主从复制**。MySQL 的恢复机制（复制其实就是在 Slave Mysql 不断做基于 BINLOG 的恢复）有以下特点：

- 一是 MySQL 的**恢复是 SQL 语句级**的，也就是重新执行 BINLOG 中的 SQL 语句。
- 二是 MySQL 的 **Binlog 是按照事务提交的先后顺序记录**的， 恢复也是按这个顺序进行的。

由此可见，MySQL 的恢复机制要求：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。





## **InnoDB 在不同隔离级别下的一致性读及锁的差异：**

**锁和多版本数据（MVCC）**是 `InnoDB` **实现一致性读**和 ISO/ANSI SQL92 **隔离级别**的手段。

(图见知乎)

对于许多 SQL，隔离级别越高，InnoDB 给记录集加的锁就越严格（尤其是使用范围条件的时候），产生锁冲突的可能性也就越高，从而对并发性事务处理性能的 影响也就越大。

因此， 我们在应用中， 应该尽量使用较低的隔离级别， 以减少锁争用的机率，大部分应用使用 `Read Commited` 隔离级别就足够了。

#### MVCC详细的见事务.md！





## **获取 InnoDB 行锁争用情况：**

可以通过检查 InnoDB_row_lock 状态变量来分析系统上的行锁的争夺情况：

```sql
mysql> show status like 'innodb_row_lock%'; 
```



=====================================================================================

# LOCK TABLES 和 UNLOCK TABLES

`Mysql`也支持lock tables和unlock tables，这都是在**服务器层（MySQL Server层）实现的**，和存储引擎无关，它们有自己的用途，并不能替代事务处理。

**对比行锁：行级锁只在存储引擎层实现，而Mysql服务器层没有实现**



- `LOCK TABLES` 可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。
- `UNLOCK TABLES` 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES 时，
  或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁



## **LOCK TABLES语法：**

- 在用 LOCK TABLES 对 InnoDB 表加锁时要注意，要将 AUTOCOMMIT 设为 0，否则MySQL 不会给表加锁；
- 事务结束前，不要用 UNLOCK TABLES 释放表锁，因为 UNLOCK TABLES会隐含地提交事务；
- COMMIT 或 ROLLBACK 并不能释放用 LOCK TABLES 加的表级锁，必须用UNLOCK TABLES 释放表锁。

正确的方式见如下语句：
例如，如果需要写表 t1 并从表 t 读，可以按如下做：

```sql
SET AUTOCOMMIT=0; 
LOCK TABLES t1 WRITE, t2 READ, ...; 
[do something with tables t1 and t2 here]; 
COMMIT; 
UNLOCK TABLES;
```

## **使用LOCK TABLES的场景：**

给表显示加表级锁（InnoDB表和MyISAM都可以），一般是为了在一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。（与MyISAM默认的表锁行为类似）



=======================================================================================

# 死锁（Deadlock Free）

- **死锁产生：**

- - 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。
  - 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。
  - 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有**双重原因：真正的数据冲突；存储引擎的实现方式。**

- **检测死锁：**数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。

- **死锁恢复：**死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，**将持有最少行级排他锁的事务进行回滚**。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。

- **外部锁的死锁检测：**发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决

- **死锁影响性能：**死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。



## **MyISAM避免死锁：**

- 在自动加锁的情况下，MyISAM 总是**一次获得 SQL 语句所需要的全部锁**，所以 MyISAM 表不会出现死锁。

## **InnoDB避免死锁：**

- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，**可以在事务开始时**通过为预期要修改的每个元祖（行）**使用SELECT ... FOR UPDATE语句**来获取必要的锁，即使这些行的更改语句是在之后才执行的。
- 在事务中，如果要更新记录，应该**直接申请足够级别的锁**，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁
- 如果事务需要修改或锁定多个表，则应在每个事务中**以相同的顺序使用加锁语句**。 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过`SELECT ... LOCK IN SHARE MODE获取行的读锁`后，如果当前事务`再需要对该记录进行更新操作`，则很有可能造成死锁。
- 改变事务隔离级别

如果出现死锁，可以用 **SHOW INNODB STATUS** 命令来**确定最后一个死锁产生的原因**。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。



## **一些优化锁性能的建议**

- 尽量使用较低的隔离级别；
- 精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会
- 选择合理的事务大小，小事务发生锁冲突的几率也更小
- 给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁
- 不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能**以固定的顺序**存取表中的行。这样可以大大减少死锁的机会
- 尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
- 不要申请超过实际需要的锁级别
- **除非必须，查询时不要显示加锁**。 **MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能**；**MVCC只在COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作**
- 对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能

















### [什么是乐观锁，什么是悲观锁](<https://www.jianshu.com/p/d2ac26ca6525>)

- 【**悲观锁**】假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。“先取锁再访问”。悲观锁修改数据之前先锁定，再修改。主要是`共享锁`（读锁）或者`排他锁`（写锁）

  **悲观锁主要是共享锁或排他锁**

  

- 【**乐观锁**】假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。

  相信事务之间的数据竞争(data race)的概率是比较小的，因此**尽可能直接做下去**，直到**提交的时候才去锁定**。**在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测**，如果发现冲突了，则返回给用户错误的信息，让用户决定如何去做。所以**不会产生任何锁和死锁**。

  相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是**记录数据版本**。

  **乐观锁适用于多读的应用类型**，这样可以提高吞吐量，像数据库如果提供类似于write_condition**机制的其实都是提供的乐观锁**。





### **实现并发控制的主要手段**

 **大致可以分为乐观并发控制和悲观并发控制两种。**

 在开始介绍之前要明确一下：无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。其实不仅仅是关系型数据库系统中有乐观锁和悲观锁的概念，像hibernate、tair、memcache等都有类似的概念。所以，**不应该拿乐观锁、悲观锁和其他的数据库锁等进行对比**。



# 实现方式

## 悲观锁实现方式

悲观锁的实现，**往往依靠数据库提供的锁机制**。在数据库中，悲观锁的流程如下：

1. 在对记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。
2. 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。具体响应方式由开发者根据实际需要决定。
3. 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。
4. 期间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

**拿比较常用的MySql Innodb引擎举例，来说明一下在SQL中如何使用悲观锁。**

要使用悲观锁，我们必须关闭MySQL数据库的自动提交属性。因为MySQL默认使用autocommit模式，也就是说，当我们执行一个更新操作后，MySQL会立刻将结果进行提交。（sql语句：set autocommit=0）

以淘宝下单过程中扣减库存的需求说明一下悲观锁的使用：



![img](https:////upload-images.jianshu.io/upload_images/7038163-6cc15e52ffa4f893.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/503/format/webp)

悲观锁使用

以上，在对id = 1的记录修改前，先通过for update的方式进行加锁，然后再进行修改。这就是比较典型的悲观锁策略。

如果以上修改库存的代码发生并发，同一时间只有一个线程可以开启事务并获得id=1的锁，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。

上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，**如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。**

## 乐观锁实现方式

使用乐观锁就不需要借助数据库的锁机制了。

乐观锁的概念中其实已经阐述了它的具体实现细节。主要就是两个步骤：**冲突检测和数据更新**。其实现方式有一种比较典型的就是**CAS**(Compare and Swap)。

CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

比如前面的扣减库存问题，通过乐观锁可以实现如下：



![img](https:////upload-images.jianshu.io/upload_images/7038163-623702054ade5d92.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/490/format/webp)

乐观锁使用

以上，我们在更新之前，先查询一下库存表中当前库存数（quantity），然后在做update的时候，以库存数作为一个修改条件。当我们提交更新的时候，判断数据库表对应记录的当前库存数与第一次取出来的库存数进行比对，如果数据库表当前库存数与第一次取出来的库存数相等，则予以更新，否则认为是过期数据。

以上更新语句存在一个比较重要的问题，即传说中的**ABA问题**。

比如说一个线程one从数据库中取出库存数3，这时候另一个线程two也从数据库中取出库存数3，并且two进行了一些操作变成了2，然后two又将库存数变成3，这时候线程one进行CAS操作发现数据库中仍然是3，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。



![img](https:////upload-images.jianshu.io/upload_images/7038163-796cf21addd6659b.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)

ABA

有一个比较好的办法可以解决ABA问题，那就是**通过一个单独的可以顺序递增的version字段**。改为以下方式即可：



![img](https:////upload-images.jianshu.io/upload_images/7038163-2b98e0c34958d656.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/631/format/webp)

ABA解决

乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行+1操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现ABA问题，因为版本号只会增加不会减少。



![img](https:////upload-images.jianshu.io/upload_images/7038163-416aa2fdc4392d1c.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)

ABA的解决

除了version以外，还可以使用时间戳，因为时间戳天然具有顺序递增性。
 以上SQL其实还是有一定的问题的，就是一旦遇上高并发的时候，**就只有一个线程可以修改成功，那么就会存在大量的失败**。

对于像淘宝这样的电商网站，高并发是常有的事，总让用户感知到失败显然是不合理的。所以，还是要**想办法减少乐观锁的粒度**的。

有一条比较好的建议，可以减小乐观锁力度，最大程度的提升吞吐率，提高并发能力！如下：



![img](https:////upload-images.jianshu.io/upload_images/7038163-f176266a4a5136d6.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/427/format/webp)

优化

以上SQL语句中，如果用户下单数为1，则通过**quantity - 1 > 0的方式进行乐观锁控制**。

以上update语句，在执行过程中，会在一次原子操作中自己查询一遍quantity的值，并将其扣减掉1。

高并发环境下锁粒度把控是一门重要的学问，选择一个好的锁，在保证数据安全的情况下，可以大大提升吞吐率，进而提升性能

# 如何选择

在乐观锁与悲观锁的选择上面，主要看下两者的区别以及适用场景就可以了。

1. **乐观锁**并未真正加锁，效率高。一旦锁的粒度掌握不好，更新失败的概率就会比较高，容易发生业务失败。
2. **悲观锁**依赖数据库锁，效率低。更新失败的概率比较低。

随着互联网三高架构（高并发、高性能、高可用）的提出，悲观锁已经越来越少的被使用到生产环境中了，尤其是并发量比较大的业务场景。



　**补充：**

　　**1、事务隔离级别为读提交时，写数据只会锁住相应的行**

　　**2、事务隔离级别为可重复读时，如果检索条件有索引（包括主键索引）的时候，默认加锁方式是next-key 锁；如果检索条件没有索引，更新数据时会锁住整张表。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读。**

　　**3、事务隔离级别为串行化时，读写数据都会锁住整张表**

　　 **4、隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。**

　　 **5、MYSQL MVCC实现机制参考链接：https://blog.csdn.net/whoamiyang/article/details/51901888**

　　 **6、关于next-key 锁可以参考链接：https://blog.csdn.net/bigtree_3721/article/details/73731377**